{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2565092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "#%% Functions\n",
    "\n",
    "# Function to get the email body\n",
    "def get_email_body(Data_Directory, Label_Directory):\n",
    "    listOfFiles = list()\n",
    "    for (dirpath, dirnames, filenames) in tqdm(os.walk(Data_Directory)):\n",
    "        listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "        data=[]\n",
    "    for f in tqdm(listOfFiles, leave=False):\n",
    "        with open (f, \"r\", encoding=\"cp437\") as myfile:\n",
    "            file = myfile.read()\n",
    "            r = r'(?P<header>[^\\n\\n]*)\\n\\n(?P<body>[\\s\\S]*)\\n'\n",
    "            for match in re.finditer(r, file):\n",
    "                data.append(match.group('body'))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    labels = pd.read_csv(Label_Directory, header = None)\n",
    "    HamOrSpam = labels[0].str.split(\" \", n = 1, expand = True)\n",
    "    df1['Status']= HamOrSpam[0]\n",
    "    df1.columns.values[0] = \"Email Content\"\n",
    "    return df1\n",
    "\n",
    "# Function to get Train and Test Data\n",
    "def data_set (data, size):\n",
    "    df = data.sample(frac=1)\n",
    "    train_size = int(size*len(df))\n",
    "    train_set = df[:train_size]\n",
    "    test_set = df[train_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "# Function to get Spam and Ham\n",
    "def spam_ham (dataset,status):\n",
    "    if status == True:\n",
    "        return dataset.loc[dataset['Status'] == 'spam']\n",
    "    else:\n",
    "        return dataset.loc[dataset['Status'] == 'ham']\n",
    "\n",
    "# Function to get Vocabulary Training\n",
    "def vocabulary (data):\n",
    "    words=[]\n",
    "    for i in tqdm(data):\n",
    "        Word_by_Email = re.sub('[^a-z\\s]+',' ',i,flags=re.IGNORECASE)\n",
    "        Word_by_Email = re.sub('(\\s+)',' ',Word_by_Email)\n",
    "        Word_by_Email = Word_by_Email.lower()\n",
    "        #Word_by_Email = re.sub('\\s+(a|div|an|and|the)(\\s+)', '\\2', Word_by_Email)\n",
    "        Word_by_Email = re.sub(r'(?:^| )\\w(?:$| )', ' ', Word_by_Email).strip()\n",
    "        Word_by_Email = Word_by_Email.split()\n",
    "        words.append(Word_by_Email)\n",
    "    \n",
    "    Word_List = pd.Series(words).explode()\n",
    "    BoW = pd.DataFrame.from_dict(Word_List)\n",
    "    BoW_Count = BoW.groupby(BoW.columns.tolist(),as_index=False).size().sort_values(by='size',ascending = False)\n",
    "    return BoW_Count, BoW\n",
    "\n",
    "# Function to get Vocabulary Testing\n",
    "def test_vocabulary(testdata):\n",
    "    words=[]\n",
    "    for i in tqdm(testdata):\n",
    "        Word_by_Email = re.sub('[^a-z\\s]+',' ',i,flags=re.IGNORECASE)\n",
    "        Word_by_Email = re.sub('(\\s+)',' ',Word_by_Email)\n",
    "        Word_by_Email = Word_by_Email.lower()\n",
    "        #Word_by_Email = re.sub('\\s+(a|div|font|html|charset|an|and|the|b|e|f|c|)(\\s+)', '\\2', Word_by_Email)\n",
    "        Word_by_Email = re.sub(r'(?:^| )\\w(?:$| )', ' ', Word_by_Email).strip()\n",
    "        Word_by_Email = Word_by_Email.split()\n",
    "        words.append(Word_by_Email)\n",
    "    return words\n",
    "\n",
    "# Get Conditional Probabilities\n",
    "def conditional_probability(BOWTrainSet, Train_Vocabulary, smoothing):\n",
    "    BoWTrainSet_ = pd.DataFrame([i for i in tqdm(Train_Vocabulary) if i in BoWTrainSet])\n",
    "    BoW_Count = BoWTrainSet_.groupby(BoWTrainSet_.columns.tolist(),as_index=False).size().sort_values(by='size',ascending = False)\n",
    "    BoW_Count['Add1'] = BoW_Count['size']+1\n",
    "\n",
    "    BOW_2 = pd.DataFrame(list(BoWTrainSet - set(Train_Vocabulary)))\n",
    "    BOW_2Count = BOW_2.groupby(BOW_2.columns.tolist(),as_index=False).size().sort_values(by='size',ascending = False)\n",
    "    BOW_2Count['Add1'] = smoothing\n",
    "    BOW = BoW_Count.append(BOW_2Count)\n",
    "\n",
    "    TotalWords = sum(BoW_Count['size'])\n",
    "\n",
    "    BOW['CondProb'] = [x/(TotalWords + len(BoW_Count['size'])*smoothing) for x in tqdm(BOW['Add1'])]\n",
    "\n",
    "    return BOW\n",
    "\n",
    "#Classify Email\n",
    "def classify_email(Probability_SpamEmail,Probability_HamEmail):\n",
    "    Classification = max({'spam':Probability_SpamEmail, 'ham':Probability_HamEmail},key={'spam':Probability_SpamEmail, 'ham':Probability_HamEmail}.get)\n",
    "    return Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ba664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "Data_Directory = 'C:/Spam_Filter/trec06p-cs280/trec06p-cs280/data'\n",
    "Label_Directory = 'C:/Spam_Filter/trec06p-cs280/trec06p-cs280/labels'\n",
    "\n",
    "#Get dataset and partition to train and test dataset\n",
    "data = get_email_body(Data_Directory, Label_Directory)\n",
    "train_set = data_set(data, 0.7)[0]\n",
    "test_set = data_set(data,0.7)[1] \n",
    "\n",
    "#%%\n",
    "#Train Dataset\n",
    "\n",
    "#Spam Training Set\n",
    "train_spam_set = spam_ham(train_set,True)\n",
    "Train_Spam_Vocabulary = vocabulary(train_spam_set['Email Content'])\n",
    "\n",
    "#Ham Training Set\n",
    "train_ham_set = spam_ham(train_set,False)\n",
    "Train_Ham_Vocabulary = vocabulary(train_ham_set['Email Content'])\n",
    "\n",
    "#All Training Set\n",
    "Train_Set_Vocabulary = vocabulary(train_set['Email Content'])\n",
    "\n",
    "Train_TotalSpam = len(train_spam_set)\n",
    "Train_TotalHam = len(train_ham_set)\n",
    "Train_SetTotal = Train_TotalSpam + Train_TotalHam\n",
    "\n",
    "#%%\n",
    "#Prior Probability of Spam and Ham in Training Set\n",
    "PriorProb_Spam = Train_TotalSpam/Train_SetTotal\n",
    "PriorProb_Ham = Train_TotalHam/Train_SetTotal\n",
    "print( PriorProb_Spam, PriorProb_Ham)\n",
    "#%% Training \n",
    "\n",
    "BoWTrainSet = set(Train_Set_Vocabulary[0][0])\n",
    "\n",
    "BOW_Spam = conditional_probability(BoWTrainSet, Train_Spam_Vocabulary[1][0], 1)\n",
    "BOW_Ham = conditional_probability(BoWTrainSet, Train_Ham_Vocabulary[1][0], 1)\n",
    "\n",
    "SpamCount = {'words': BOW_Spam[0], 'values':BOW_Spam['CondProb']}\n",
    "HamCount = {'words': BOW_Ham[0], 'values':BOW_Ham['CondProb']}\n",
    "\n",
    "#%% Testing\n",
    "Test_Vocabulary = test_vocabulary(test_set['Email Content'])\n",
    "\n",
    "classify = []\n",
    "ham=[]\n",
    "spam=[]\n",
    "SpamCountDict = dict(zip(*SpamCount.values()))\n",
    "HamCountDict = dict(zip(*HamCount.values()))\n",
    "\n",
    "for email in tqdm(Test_Vocabulary):\n",
    "    SP = [SpamCountDict[i] for i in email if i in SpamCountDict] + [1 for i in email if i not in SpamCountDict]\n",
    "    HP = [HamCountDict[i] for i in email if i in HamCountDict] + [1 for i in email if i not in HamCountDict]\n",
    "    \n",
    "    LogSpam = np.log(SP)\n",
    "    LogHam = np.log(HP)\n",
    "    Probability_SpamEmail = sum(LogSpam) + np.log(PriorProb_Spam)\n",
    "    Probability_HamEmail = sum(LogHam) + np.log(PriorProb_Ham)\n",
    "    \n",
    "    spam.append(Probability_SpamEmail)\n",
    "    ham.append(Probability_HamEmail)\n",
    "    classify.append(classify_email(Probability_SpamEmail,Probability_HamEmail))\n",
    "\n",
    "test_set['Spam Probability'] = spam\n",
    "test_set['Ham Probability'] = ham\n",
    "test_set['Classification'] = classify\n",
    "\n",
    "#%% Precision & Recall\n",
    "\n",
    "TN = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "TP = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "FP = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "FN = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "\n",
    "#%% Save dataset to file\n",
    "test_set.to_csv('normal_test_set.csv')\n",
    "BOW_Spam.to_csv('normal_spam_words.csv')\n",
    "BOW_Ham.to_csv('normal_ham_words.csv')\n",
    "\n",
    "#%% Lambda Smoothing Function\n",
    "\n",
    "def lambda_smoothing(BoWTrainSet, Train_Spam_Vocabulary,Train_Ham_Vocabulary, Test_Vocabulary, lambda_smoothing):\n",
    "    \n",
    "    BOW_Spam = conditional_probability(BoWTrainSet, Train_Spam_Vocabulary[1][0], lambda_smoothing)\n",
    "    BOW_Ham = conditional_probability(BoWTrainSet, Train_Ham_Vocabulary[1][0], lambda_smoothing)\n",
    "    \n",
    "    SpamCount = {'words': BOW_Spam[0], 'values':BOW_Spam['CondProb']}\n",
    "    HamCount = {'words': BOW_Ham[0], 'values':BOW_Ham['CondProb']}\n",
    "    \n",
    "    classify = []\n",
    "    ham=[]\n",
    "    spam=[]\n",
    "    SpamCountDict = dict(zip(*SpamCount.values()))\n",
    "    HamCountDict = dict(zip(*HamCount.values()))\n",
    "    for email in tqdm(Test_Vocabulary):\n",
    "        SP = [SpamCountDict[i] for i in email if i in SpamCountDict] + [1 for i in email if i not in SpamCountDict]\n",
    "        HP = [HamCountDict[i] for i in email if i in HamCountDict] + [1 for i in email if i not in HamCountDict]\n",
    "        \n",
    "        LogSpam = np.log(SP)\n",
    "        LogHam = np.log(HP)\n",
    "        Probability_SpamEmail = sum(LogSpam) + np.log(PriorProb_Spam)\n",
    "        Probability_HamEmail = sum(LogHam) + np.log(PriorProb_Ham)\n",
    "        \n",
    "        spam.append(Probability_SpamEmail)\n",
    "        ham.append(Probability_HamEmail)\n",
    "        classify.append(classify_email(Probability_SpamEmail,Probability_HamEmail))\n",
    "\n",
    "    test_set['Spam Probability'] = spam\n",
    "    test_set['Ham Probability'] = ham\n",
    "    test_set['Classification'] = classify\n",
    "    \n",
    "    TN = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "    TP = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "    FP = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "    FN = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "    \n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP/(TP+FN)\n",
    "    \n",
    "    return Precision,Recall\n",
    "\n",
    "#%% Precision and Recall using Different Lambda Smoothing\n",
    "\n",
    "smoothing_value = [2,1,0.5,0.1,0.005]\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in smoothing_value:\n",
    "    result = lambda_smoothing(BoWTrainSet, Train_Spam_Vocabulary,Train_Ham_Vocabulary, Test_Vocabulary,i)\n",
    "    precision.append(result[0])\n",
    "    recall.append(result[1])\n",
    "\n",
    "#%% Plot\n",
    "\n",
    "plt.plot(smoothing_value, precision, label='Precision',  marker='o')\n",
    "plt.plot(smoothing_value, recall, label='Recal', marker='x')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Precision and Recall of Different Lambda Smoothing')\n",
    "plt.ylabel('Precision and Recall')\n",
    "plt.xlabel('Lambda Smoothing')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Improving Classifier \n",
    "\n",
    "# 200 of the Mostly Used Words in the Dataset\n",
    "Words200Spam = (BOW_Spam[0:200][0]).to_list()\n",
    "Words200Ham = (BOW_Ham[0:200][0]).to_list()\n",
    "Train200 = (Train_Set_Vocabulary[0][0:200][0]).to_list()\n",
    "\n",
    "# Function to get Vocabulary Training\n",
    "def vocabulary_improve (data, Words200):\n",
    "    words=[]\n",
    "    remove = '|'.join(Words200)\n",
    "    for i in tqdm(data):\n",
    "        Word_by_Email = re.sub('[^a-z\\s]+',' ',i,flags=re.IGNORECASE)\n",
    "        Word_by_Email = re.sub('(\\s+)',' ',Word_by_Email)\n",
    "        Word_by_Email = Word_by_Email.lower()\n",
    "        Word_by_Email = re.sub('\\s+('+ remove +')(\\s+)', '\\2', Word_by_Email)\n",
    "        Word_by_Email = re.sub(r'(?:^| )\\w(?:$| )', ' ', Word_by_Email).strip()\n",
    "        Word_by_Email = Word_by_Email.split()\n",
    "        words.append(Word_by_Email)\n",
    "    \n",
    "    Word_List = pd.Series(words).explode()\n",
    "    BoW = pd.DataFrame.from_dict(Word_List)\n",
    "    BoW_Count = BoW.groupby(BoW.columns.tolist(),as_index=False).size().sort_values(by='size',ascending = False)\n",
    "    return BoW_Count, BoW\n",
    "\n",
    "# Function to get Vocabulary Testing\n",
    "def test_vocabulary_improve(testdata, Words200):\n",
    "    words=[]\n",
    "    remove = '|'.join(Words200)\n",
    "    for i in tqdm(testdata):\n",
    "        Word_by_Email = re.sub('[^a-z\\s]+',' ',i,flags=re.IGNORECASE)\n",
    "        Word_by_Email = re.sub('(\\s+)',' ',Word_by_Email)\n",
    "        Word_by_Email = Word_by_Email.lower()\n",
    "        Word_by_Email = re.sub('\\s+('+ remove +')(\\s+)', '\\2', Word_by_Email)\n",
    "        Word_by_Email = re.sub(r'(?:^| )\\w(?:$| )', ' ', Word_by_Email).strip()\n",
    "        Word_by_Email = Word_by_Email.split()\n",
    "        words.append(Word_by_Email)\n",
    "    return words\n",
    "\n",
    "#%%\n",
    "#Train Dataset\n",
    "\n",
    "#Spam Training Set\n",
    "train_spam_set = spam_ham(train_set,True)\n",
    "Train_Spam_Vocabulary = vocabulary_improve(train_spam_set['Email Content'],Words200Spam)\n",
    "\n",
    "#Ham Training Set\n",
    "train_ham_set = spam_ham(train_set,False)\n",
    "Train_Ham_Vocabulary = vocabulary_improve(train_ham_set['Email Content'],Words200Ham)\n",
    "\n",
    "#All Training Set\n",
    "Train_Set_Vocabulary = vocabulary_improve(train_set['Email Content'],Train200)\n",
    "\n",
    "Train_TotalSpam = len(train_spam_set)\n",
    "Train_TotalHam = len(train_ham_set)\n",
    "Train_SetTotal = Train_TotalSpam + Train_TotalHam\n",
    "\n",
    "#%%\n",
    "#Prior Probability of Spam and Ham in Training Set\n",
    "PriorProb_Spam = Train_TotalSpam/Train_SetTotal\n",
    "PriorProb_Ham = Train_TotalHam/Train_SetTotal\n",
    "print( PriorProb_Spam, PriorProb_Ham)\n",
    "#%% Training \n",
    "\n",
    "BoWTrainSet = set(Train_Set_Vocabulary[0][0])\n",
    "\n",
    "BOW_Spam = conditional_probability(BoWTrainSet, Train_Spam_Vocabulary[1][0], 1)\n",
    "BOW_Ham = conditional_probability(BoWTrainSet, Train_Ham_Vocabulary[1][0], 1)\n",
    "\n",
    "SpamCount = {'words': BOW_Spam[0], 'values':BOW_Spam['CondProb']}\n",
    "HamCount = {'words': BOW_Ham[0], 'values':BOW_Ham['CondProb']}\n",
    "\n",
    "#%% Testing\n",
    "Test_Vocabulary = test_vocabulary(test_set['Email Content'])\n",
    "\n",
    "classify = []\n",
    "ham=[]\n",
    "spam=[]\n",
    "SpamCountDict = dict(zip(*SpamCount.values()))\n",
    "HamCountDict = dict(zip(*HamCount.values()))\n",
    "for email in tqdm(Test_Vocabulary):\n",
    "    SP = [SpamCountDict[i] for i in email if i in SpamCountDict] + [1 for i in email if i not in SpamCountDict]\n",
    "    HP = [HamCountDict[i] for i in email if i in HamCountDict] + [1 for i in email if i not in HamCountDict]\n",
    "    \n",
    "    LogSpam = np.log(SP)\n",
    "    LogHam = np.log(HP)\n",
    "    Probability_SpamEmail = sum(LogSpam) + np.log(PriorProb_Spam)\n",
    "    Probability_HamEmail = sum(LogHam) + np.log(PriorProb_Ham)\n",
    "    \n",
    "    spam.append(Probability_SpamEmail)\n",
    "    ham.append(Probability_HamEmail)\n",
    "    classify.append(classify_email(Probability_SpamEmail,Probability_HamEmail))\n",
    "\n",
    "test_set['Spam Probability'] = spam\n",
    "test_set['Ham Probability'] = ham\n",
    "test_set['Classification'] = classify\n",
    "\n",
    "#%% Precision & Recall\n",
    "\n",
    "TN = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "TP = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "FP = test_set.loc[(test_set['Status'] == 'ham') & (test_set['Classification'] == 'spam')].count()[0]\n",
    "FN = test_set.loc[(test_set['Status'] == 'spam') & (test_set['Classification'] == 'ham')].count()[0]\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "print(Precision)\n",
    "print(Recall)\n",
    "\n",
    "#%% Precision and Recall using Different Lambda Smoothing\n",
    "\n",
    "smoothing_value = [2,1,0.5,0.1,0.005]\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in smoothing_value:\n",
    "    result = lambda_smoothing(BoWTrainSet, Train_Spam_Vocabulary,Train_Ham_Vocabulary, Test_Vocabulary,i)\n",
    "    precision.append(result[0])\n",
    "    recall.append(result[1])\n",
    "\n",
    "#%% Plot\n",
    "\n",
    "plt.plot(smoothing_value, precision, label='Precision',  marker='o')\n",
    "plt.plot(smoothing_value, recall, label='Recal', marker='x')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Precision and Recall of Improved Classifier')\n",
    "plt.ylabel('Precision and Recall')\n",
    "plt.xlabel('Lambda Smoothing')\n",
    "plt.show()\n",
    "\n",
    "#%%Save Improved Dataset to File\n",
    "test_set.to_csv('improved_test_set.csv')\n",
    "BOW_Spam.to_csv('improved_spam_words.csv')\n",
    "BOW_Ham.to_csv('improved_ham_words.csv')\n",
    "train_set.to_csv('trainset.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
